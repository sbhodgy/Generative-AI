{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125b6755",
   "metadata": {},
   "source": [
    "## LangGraph Quickstart <img src=\"../../images/db-icon.png\" width=25 />\n",
    "In this tutorial, we will build a support chatbot in LangGraph that can:\n",
    "\n",
    "âœ… Answer common questions by searching the web<br>\n",
    "âœ… Maintain conversation state across calls<br>\n",
    "âœ… Route complex queries to a human for review<br>\n",
    "âœ… Use custom state to control its behavior<br>\n",
    "âœ… Rewind and explore alternative conversation paths\n",
    "\n",
    "We'll start with a basic chatbot and progressively add more sophisticated capabilities, introducing key LangGraph concepts along the way. Letâ€™s dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4989c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Part 1: Build a Basic Chatbot\n",
    "We'll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\n",
    "\n",
    "Start by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We'll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a89d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ffd2e",
   "metadata": {},
   "source": [
    "Our graph can now handle two key tasks:\n",
    "\n",
    "1. Each ```node``` can receive the current ```State``` as input and output an update to the state.\n",
    "1. Updates to ```messages``` will be appended to the existing list rather than overwriting it, thanks to the prebuilt ```add_messages``` function used with the ```Annotated``` syntax.\n",
    "\n",
    "Next, add a \"```chatbot```\" node. Nodes represent units of work. They are typically regular python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "llm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-3-70b-instruct\", temperature=0)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad971c",
   "metadata": {},
   "source": [
    "Notice how the ```chatbot``` node function takes the current ```State``` as input and returns a dictionary containing an updated ```messages``` list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\n",
    "\n",
    "The ```add_messages``` function in our ```State``` will append the llm's response messages to whatever messages are already in the state.\n",
    "\n",
    "Next, add an ```entry``` point. This tells our graph **where to start its work** each time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99782b7",
   "metadata": {},
   "source": [
    "Similarly, set a ```finish``` point. This instructs the graph **\"any time this node is run, you can exit.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9502e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99d2f8",
   "metadata": {},
   "source": [
    "Finally, we'll want to be able to run our graph.<br>\n",
    "To do so, call ```compile()``` on the graph builder. This creates a \"```CompiledGraph```\" we can use invoke on our state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024399a1",
   "metadata": {},
   "source": [
    "You can visualize the graph using the ```get_graph``` method and one of the \"draw\" methods, like ```draw_ascii``` or ```draw_png```.<br>\n",
    "The draw methods each require additional dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703cdcd",
   "metadata": {},
   "source": [
    "Now let's run the chatbot!\n",
    "\n",
    "**Tip:** You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d399d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "user_input = \"What do you know about LangGraph?\"\n",
    "print(\"User: \" + user_input)\n",
    "stream_graph_updates(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae85ca2",
   "metadata": {},
   "source": [
    "Congratulations! You've built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a [LangSmith Trace](https://smith.langchain.com/public/7527e308-9502-4894-b347-f34385740d5a/r) for the call above at the provided link.\n",
    "However, you may have noticed that the bot's knowledge is limited to what's in its training data. In the next part, we'll add a web search tool to expand the bot's knowledge and make it more capable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c7623",
   "metadata": {},
   "source": [
    "### Part 2: ðŸ› ï¸ Enhancing the Chatbot with ToolsÂ¶\n",
    "To handle queries our chatbot can't answer \"from memory\", we'll integrate a web search tool. Our bot can use this tool to find relevant information and provide better responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be550c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9aa3e4",
   "metadata": {},
   "source": [
    "The results are page summaries our chat bot can use to answer questions.\n",
    "\n",
    "Next, we'll start defining our graph. The following is **all the same as in Part 1**, except we have added ```bind_tools``` on our LLM.This lets the LLM know the correct JSON format to use if it wants to use our search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414cbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-3-70b-instruct\", temperature=0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca35a5",
   "metadata": {},
   "source": [
    "Next we need to create a function to actually run the tools if they are called. We'll do this by adding the tools to a new node.\n",
    "\n",
    "Below, we implement a ```BasicToolNode``` that checks the most recent message in the state and calls tools if the message contains ```tool_calls```. It relies on the LLM's ```tool_calling``` support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\n",
    "\n",
    "We will later replace this with LangGraph's prebuilt ToolNode to speed things up, but building it ourselves first is instructive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3589d",
   "metadata": {},
   "source": [
    "With the tool node added, we can define the ```conditional_edges```.\n",
    "\n",
    "Recall that **edges** route the control flow from one node to the next. **Conditional edges** usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\n",
    "\n",
    "Below, call define a router function called ```route_tools```, that checks for tool_calls in the chatbot's output. Provide this function to the graph by calling ```add_conditional_edges```, which tells the graph that whenever the ```chatbot``` node completes to check this function to see where to go next.\n",
    "\n",
    "The condition will route to ```tools``` if tool calls are present and ```END``` if not.\n",
    "\n",
    "Later, we will replace this with the prebuilt tools_condition to be more concise, but implementing it ourselves first makes things more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3160a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(state: State,):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3511e5",
   "metadata": {},
   "source": [
    "Notice that conditional edges start from a single node. This tells the graph \"any time the 'chatbot' node runs, either go to 'tools' if it calls a tool, or end the loop if it responds directly.\n",
    "\n",
    "Like the prebuilt tools_condition, our function returns the END string if no tool calls are made. When the graph transitions to END, it has no more tasks to complete and ceases execution. Because the condition can return END, we don't need to explicitly set a finish_point this time. Our graph already has a way to finish!\n",
    "\n",
    "Let's visualize the graph we've built. The following function has some additional dependencies to run that are unimportant for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e870688",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What do you know about LangGraph?\"\n",
    "print(\"User: \" + user_input)\n",
    "stream_graph_updates(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
