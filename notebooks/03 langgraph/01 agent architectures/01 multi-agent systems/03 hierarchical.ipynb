{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4d1c36",
   "metadata": {},
   "source": [
    "## Hierarchical Agent Teams <img src=\"../../../../images/openai-icon.png\" width=30 />\n",
    "In our previous example (Agent Supervisor), we introduced the concept of a single supervisor node to route work between different worker nodes.\n",
    "\n",
    "But what if the job for a single worker becomes too complex? What if the number of workers becomes too large?\n",
    "\n",
    "For some applications, the system may be more effective if work is distributed hierarchically.\n",
    "\n",
    "You can do this by composing different subgraphs and creating a top-level supervisor, along with mid-level supervisors.\n",
    "\n",
    "To do this, let's build a simple research assistant! The graph will look something like the following:\n",
    "\n",
    "<img src=\"../../../../images/multi-agent-hierarchical.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03c650",
   "metadata": {},
   "source": [
    "In the rest of this notebook, you will:\n",
    "\n",
    "1. Define the agents' tools to access the web and write files\n",
    "2. Define some utilities to help create the graph and agents\n",
    "3. Create and define each team (web research + doc writing)\n",
    "4. Compose everything together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f751799",
   "metadata": {},
   "source": [
    "### Create Tools\n",
    "Each team will be composed of one or more agents each with one or more tools. Below, define all the tools to be used by your different teams.\n",
    "\n",
    "We'll start with the research team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1eef95",
   "metadata": {},
   "source": [
    "#### Research Team tools\n",
    "\n",
    "The research team can use a search engine and url scraper to find information on the web. Feel free to add additional functionality below to boost the team performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3dfce",
   "metadata": {},
   "source": [
    "##### Tavily Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5dd4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf497b",
   "metadata": {},
   "source": [
    "##### Webpage Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611478ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def scrape_webpages(urls: List[str]) -> str:\n",
    "    \"\"\"Use requests and bs4 to scrape the provided web pages for detailed information.\"\"\"\n",
    "    loader = WebBaseLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document name=\"{doc.metadata.get(\"title\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f2c09",
   "metadata": {},
   "source": [
    "#### Document Team Tools\n",
    "\n",
    "Next up, we will give some tools for the doc writing team to use. We define some bare-bones file-access tools below.\n",
    "\n",
    "**Note:** this gives the agents access to your file-system, which can be unsafe. We also haven't optimized the tool descriptions for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# from tempfile import TemporaryDirectory\n",
    "\n",
    "# Define a temporary directory within the current working directory\n",
    "base_directory = Path.cwd() / \"writer_agent_temp\"\n",
    "base_directory.mkdir(exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "WORKING_DIRECTORY = Path(base_directory.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3f93b",
   "metadata": {},
   "source": [
    "##### Create Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
    ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "    \"\"\"Create and save an outline.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        for i, point in enumerate(points):\n",
    "            file.write(f\"{i + 1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f04f5b",
   "metadata": {},
   "source": [
    "##### Read Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0440d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to read the document from.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac6aa1",
   "metadata": {},
   "source": [
    "##### Write Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555c947",
   "metadata": {},
   "source": [
    "##### Edit Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "    inserts: Annotated[\n",
    "        Dict[int, str],\n",
    "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "    ],\n",
    ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sorted_inserts = sorted(inserts.items())\n",
    "\n",
    "    for line_number, text in sorted_inserts:\n",
    "        if 1 <= line_number <= len(lines) + 1:\n",
    "            lines.insert(line_number - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return f\"Document edited and saved to {file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6b036",
   "metadata": {},
   "source": [
    "##### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb75a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    return f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1f3dc",
   "metadata": {},
   "source": [
    "#### Helper Utilities\n",
    "We are going to create a few utility functions to make it more concise when we want to:\n",
    "\n",
    "1. Create a worker agent.\n",
    "2. Create a supervisor for the sub-graph.\n",
    "\n",
    "These will simplify the graph compositional code at the end for us so it's easier to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypedDict\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "# from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def make_supervisor_node(llm: BaseChatModel, members: list[str]) -> str:\n",
    "    options = [\"FINISH\"] + members\n",
    "    system_prompt = (\n",
    "        \"You are a supervisor tasked with managing a conversation between the\"\n",
    "        f\" following workers: {members}. Given the following user request,\"\n",
    "        \" respond with the worker to act next. Each worker will perform a\"\n",
    "        \" task and respond with their results and status. When finished,\"\n",
    "        \" respond with FINISH.\"\n",
    "    )\n",
    "\n",
    "    class Router(TypedDict):\n",
    "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "        next: Literal[*options]\n",
    "\n",
    "    def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "        \"\"\"An LLM-based router.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + state[\"messages\"]\n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "        if goto == \"FINISH\":\n",
    "            goto = END\n",
    "\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "    return supervisor_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00873e10",
   "metadata": {},
   "source": [
    "### Define Agent Teams\n",
    "Now we can get to define our hierarchical teams. \"Choose your player!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd3f81",
   "metadata": {},
   "source": [
    "#### Research Team\n",
    "The research team will have a search agent and a web scraping \"research_agent\" as the two worker nodes. Let's create those, as well as the team supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c654a2",
   "metadata": {},
   "source": [
    "##### Web Search Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed06c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "search_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "\n",
    "def search_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c832c74",
   "metadata": {},
   "source": [
    "##### Web Scraper Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae753de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scraper_agent = create_react_agent(llm, tools=[scrape_webpages])\n",
    "\n",
    "\n",
    "def web_scraper_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = web_scraper_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"web_scraper\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d0de2",
   "metadata": {},
   "source": [
    "##### Research Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a82095",
   "metadata": {},
   "source": [
    "##### Define the Graph\n",
    "Now that we've created the necessary components, defining their interactions is easy. Add the nodes to the team graph, and define the edges, which determine the transition criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "research_builder = StateGraph(State)\n",
    "research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
    "research_builder.add_node(\"search\", search_node)\n",
    "research_builder.add_node(\"web_scraper\", web_scraper_node)\n",
    "\n",
    "research_builder.add_edge(START, \"supervisor\")\n",
    "research_graph = research_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f27a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(research_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in research_graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Who won the four nations hockey tournament?\")]},\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0994d",
   "metadata": {},
   "source": [
    "#### Document Writing Team\n",
    "Create the document writing team below using a similar approach. This time, we will give each agent access to different file-writing tools.\n",
    "\n",
    "**Note:** we are giving file-system access to our agent here, which is not safe in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9d350",
   "metadata": {},
   "source": [
    "##### Document Writer Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7918eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_writer_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[write_document, edit_document, read_document],\n",
    "    prompt=(\n",
    "        \"You can read, write and edit documents based on note-taker's outlines. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "def doc_writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = doc_writer_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"doc_writer\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6aed97",
   "metadata": {},
   "source": [
    "##### Note Taking Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d31928",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_taking_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[create_outline, read_document],\n",
    "    prompt=(\n",
    "        \"You can read documents and create outlines for the document writer. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def note_taking_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = note_taking_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"note_taker\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d22b0",
   "metadata": {},
   "source": [
    "##### Chart Generation Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_generating_agent = create_react_agent(\n",
    "    llm, tools=[read_document, python_repl_tool]\n",
    ")\n",
    "\n",
    "\n",
    "def chart_generating_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = chart_generating_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee270f7b",
   "metadata": {},
   "source": [
    "##### Document Writing Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_writing_supervisor_node = make_supervisor_node(\n",
    "    llm, [\"doc_writer\", \"note_taker\", \"chart_generator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c31e5f",
   "metadata": {},
   "source": [
    "##### Define the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_writing_builder = StateGraph(State)\n",
    "paper_writing_builder.add_node(\"supervisor\", doc_writing_supervisor_node)\n",
    "paper_writing_builder.add_node(\"doc_writer\", doc_writing_node)\n",
    "paper_writing_builder.add_node(\"note_taker\", note_taking_node)\n",
    "paper_writing_builder.add_node(\"chart_generator\", chart_generating_node)\n",
    "\n",
    "paper_writing_builder.add_edge(START, \"supervisor\")\n",
    "paper_writing_graph = paper_writing_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56607aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(paper_writing_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7baf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in paper_writing_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Write an outline for poem about cats and then write the poem to disk.\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89381ad0",
   "metadata": {},
   "source": [
    "#### Add Layers\n",
    "In this design, we are enforcing a top-down planning policy. We've created two graphs already, but we have to decide how to route work between the two.\n",
    "\n",
    "We'll create a third graph to orchestrate the previous two, and add some connectors to define how this top-level state is shared between the different graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75143c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import BaseMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "teams_supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_research_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"research_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def call_paper_writing_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = paper_writing_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"writing_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9eabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_builder = StateGraph(State)\n",
    "super_builder.add_node(\"supervisor\", teams_supervisor_node)\n",
    "super_builder.add_node(\"research_team\", call_research_team)\n",
    "super_builder.add_node(\"writing_team\", call_paper_writing_team)\n",
    "\n",
    "super_builder.add_edge(START, \"supervisor\")\n",
    "super_graph = super_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc900c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(super_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b76d68",
   "metadata": {},
   "source": [
    "### Invoking the Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Write a paper on why its difficult being a Toronto Maple Leafs fan.\")\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 150},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2cca9",
   "metadata": {},
   "source": [
    "Run the remaining code to delete the temporary working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6392a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.rmtree(WORKING_DIRECTORY) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
